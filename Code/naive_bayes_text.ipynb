{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用朴素贝耶斯算法对评论进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的包\n",
    "\n",
    "import pandas as pd\n",
    "import jieba\n",
    "from gensim import corpora,models,matutils\n",
    "\n",
    "import gensim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0                                            comment grade  \\\n",
      "0             0                          2颗星给拍摄场面、给志愿军战士们，其他没法更多了。    较差   \n",
      "1             1  非常合格的献礼片，3个小时略长但是看点满满。节奏情感战争场面都处理的恰到好处。虽然是三个大导...    力荐   \n",
      "2             2                           “《长津湖》最好的彩蛋，便是今日繁荣昌盛的祖国”    力荐   \n",
      "3             3                          我觉得下次别设置这种任性小孩形象了，战争不是儿戏。    还行   \n",
      "4             4  看了点映，第七穿插连的故事有血有肉有笑有泪，很是动人。其中恢宏大场面相当有气势，虽然制作时间...    力荐   \n",
      "..          ...                                                ...   ...   \n",
      "174         175  三个小时没看够，最后戛然而止，期待下部春节上映。三个导演融合的还行，没有太大的割裂感，战争场...    力荐   \n",
      "175         176                    向英雄的致敬是无法用打分来衡量的，但是电影的呈现就那样那样吧。    还行   \n",
      "176         177                    我失望的是这么恢弘壮美的历史被拍成了一部中规中矩的普通战争片。    较差   \n",
      "177         178                                         一段意味深长的历史！    力荐   \n",
      "178         179  还是很适合普通观众进电影院去看的，时间虽然长，但节奏控制的比较好，剧情也有递进，也并不复杂，...    力荐   \n",
      "\n",
      "     grade_new  \n",
      "0            2  \n",
      "1            5  \n",
      "2            5  \n",
      "3            3  \n",
      "4            5  \n",
      "..         ...  \n",
      "174          5  \n",
      "175          3  \n",
      "176          2  \n",
      "177          5  \n",
      "178          5  \n",
      "\n",
      "[179 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# 读取数据，数据标签的雅元处理\n",
    "\n",
    "data_df  = pd.read_excel(\"./data/comment.xlsx\")\n",
    "\n",
    "# 标签哑处理\n",
    "\n",
    "grade_dict = {\"力荐\":5, \"推荐\":4, \"还行\":3, \"较差\":2, \"很差\":1}\n",
    "data_df[\"grade_new\"] = data_df[\"grade\"].map(grade_dict)\n",
    "\n",
    "\n",
    "print(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本的预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词、过滤停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "       ... \n",
       "174    None\n",
       "175    None\n",
       "176    None\n",
       "177    None\n",
       "178    None\n",
       "Name: comment, Length: 179, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pre = []\n",
    "\n",
    "# 加载停用词库\n",
    "\n",
    "with open (\"./data/哈工大停用词表.txt\") as f:\n",
    "    stop_word_list = [i.strip() for i in f.readlines()]\n",
    "\n",
    "# 定义分词、过滤停用词的函数\n",
    "\n",
    "def division_stop_word(text):\n",
    "\n",
    "    division_word = jieba.lcut(text)\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    for i in division_word:\n",
    "        if i>=u\"\\u4e00\" and i<= u\"\\u9fa5\":\n",
    "            if i not in stop_word_list:\n",
    "                result_list.append(i)\n",
    "\n",
    "    word_pre.append(result_list)\n",
    "\n",
    "data_df[\"comment\"].apply(lambda x: division_stop_word(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成文本向量矩阵、词袋、语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.interfaces.TransformedCorpus object at 0x7f1b58e100a0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 生成语料\n",
    "\n",
    "dictionary  = corpora.Dictionary(word_pre)\n",
    "\n",
    "# 生成词袋\n",
    "\n",
    "word_bow = [dictionary.doc2bow(text) for text in word_pre]\n",
    "\n",
    "# 通过词袋训练模型\n",
    "\n",
    "tfidf = models.TfidfModel(word_bow)\n",
    "\n",
    "# 得出词的权重\n",
    "\n",
    "word_weight = tfidf[word_bow]\n",
    "\n",
    "\n",
    "\n",
    "# 文本的特征数量组成向量矩阵\n",
    "word_matrix = matutils.corpus2dense(word_weight,num_terms=len(dictionary.token2id.keys())).T\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9888268156424581"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入算法、训练算法\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB  # 高斯分布\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB # 多项式分布\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB # 二项分布\n",
    "\n",
    "\n",
    "gsnb = GaussianNB()\n",
    "\n",
    "gsnb.fit(word_matrix,data_df[\"grade_new\"])\n",
    "\n",
    "gsnb.score(word_matrix,data_df[\"grade_new\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "586ad1ed5c97141e2437e681efbf1ec0adcd17d830cf5af2ca3d2819e743e158"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
